{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑÊùÉÈáçÊñá‰ª∂\n",
    "model = YOLO(\"all_species_240916/default_args/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics 8.3.23 üöÄ Python-3.10.15 torch-2.5.0+cu124 CUDA:0 (Tesla T4, 14918MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,929,789 parameters, 0 gradients, 72.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'all_species_240916/default_args/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 1171, 8400) (40.4 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ùå AutoUpdate skipped (offline)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxslim'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.4s, saved as 'all_species_240916/default_args/weights/best.onnx' (80.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.6.0.post1...\n",
      "[11/24/2024-21:59:40] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 835, GPU 774 (MiB)\n",
      "[11/24/2024-21:59:42] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +962, GPU +194, now: CPU 1954, GPU 968 (MiB)\n",
      "[11/24/2024-21:59:42] [TRT] [I] ----------------------------------------------------------------\n",
      "[11/24/2024-21:59:42] [TRT] [I] Input filename:   all_species_240916/default_args/weights/best.onnx\n",
      "[11/24/2024-21:59:42] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[11/24/2024-21:59:42] [TRT] [I] Opset version:    19\n",
      "[11/24/2024-21:59:42] [TRT] [I] Producer name:    pytorch\n",
      "[11/24/2024-21:59:42] [TRT] [I] Producer version: 2.5.0\n",
      "[11/24/2024-21:59:42] [TRT] [I] Domain:           \n",
      "[11/24/2024-21:59:42] [TRT] [I] Model version:    0\n",
      "[11/24/2024-21:59:42] [TRT] [I] Doc string:       \n",
      "[11/24/2024-21:59:42] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 1171, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as all_species_240916/default_args/weights/best.engine\n",
      "[11/24/2024-21:59:42] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
      "[11/24/2024-21:59:42] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
      "[11/24/2024-21:59:42] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[11/24/2024-22:00:27] [TRT] [I] Compiler backend is used during engine build.\n",
      "[11/24/2024-22:01:28] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[11/24/2024-22:01:28] [TRT] [I] Total Host Persistent Memory: 493888 bytes\n",
      "[11/24/2024-22:01:28] [TRT] [I] Total Device Persistent Memory: 1905664 bytes\n",
      "[11/24/2024-22:01:28] [TRT] [I] Max Scratch Memory: 5529600 bytes\n",
      "[11/24/2024-22:01:28] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 365 steps to complete.\n",
      "[11/24/2024-22:01:29] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 37.8571ms to assign 12 blocks to 365 nodes requiring 97139712 bytes.\n",
      "[11/24/2024-22:01:29] [TRT] [I] Total Activation Memory: 97138176 bytes\n",
      "[11/24/2024-22:01:29] [TRT] [I] Total Weights Memory: 91869764 bytes\n",
      "[11/24/2024-22:01:29] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[11/24/2024-22:01:29] [TRT] [I] Engine generation completed in 106.429 seconds.\n",
      "[11/24/2024-22:01:29] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 9 MiB, GPU 2224 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 110.0s, saved as 'all_species_240916/default_args/weights/best.engine' (89.5 MB)\n",
      "\n",
      "Export complete (110.4s)\n",
      "Results saved to \u001b[1m/home/yuzhong/data1/code/object_detection/object_detection/all_species_240916/default_args/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=all_species_240916/default_args/weights/best.engine imgsz=640  \n",
      "Validate:        yolo val task=detect model=all_species_240916/default_args/weights/best.engine imgsz=640 data=./all_species_240916.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'all_species_240916/default_args/weights/best.engine'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
