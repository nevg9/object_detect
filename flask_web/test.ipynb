{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.nn.tasks import torch_safe_load, ClassificationModel\n",
    "import torch\n",
    "from safetensors.torch import load_file\n",
    "from ultralytics.data.dataset import classify_transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_model(path, nc):\n",
    "    ckpt, w = torch_safe_load(path)\n",
    "    model = ckpt[\"model\"]\n",
    "    ClassificationModel.reshape_outputs(model, nc)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False  # for training\n",
    "    model = model.float()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (2): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (4): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-3): 4 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (6): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-3): 4 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): SiLU()\n",
       "    )\n",
       "    (8): C2f(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0-1): 2 x Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Classify(\n",
       "      (conv): Conv(\n",
       "        (conv): Conv2d(768, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (drop): Dropout(p=0.0, inplace=True)\n",
       "      (linear): Linear(in_features=1280, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 0\n",
    "model_cls_ori_path = \"/mnt/data1/model_1122/image_classifier/yolov8m-cls.pt\"\n",
    "checkpoint_path = \"/mnt/data1/model_1122/image_classifier/epoch_30/model.safetensors\"\n",
    "model = load_yolo_model(model_cls_ori_path, 3)\n",
    "weights = load_file(checkpoint_path)\n",
    "model.load_state_dict(weights)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_transforms = classify_transforms(size=224) \n",
    "def process_image_classifier_image(image_binary, torch_transforms, device = 0):\n",
    "    try:\n",
    "        nparr = np.frombuffer(image_binary, np.uint8)\n",
    "        im = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # 转换为PIL图像 (RGB格式)\n",
    "        im = Image.fromarray(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "        # 应用转换\n",
    "        sample = torch_transforms(im).to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding image: {str(e)}\")\n",
    "        return None \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_and_image_file(directory, label, files_and_label):\n",
    "    supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(supported_formats):  # 检查文件扩展名\n",
    "                file_path = os.path.join(root, file)\n",
    "                files_and_label.append((file_path, label))\n",
    "    return files_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据个数:107459,随机选择的元素个数:1000\n"
     ]
    }
   ],
   "source": [
    "files_and_label = []\n",
    "files_and_label = get_label_and_image_file(\"/mnt/data1/model_1122/image_classifier/test/animal\", 0, files_and_label)\n",
    "files_and_label = get_label_and_image_file(\"/mnt/data1/model_1122/image_classifier/test/human\", 1, files_and_label)\n",
    "files_and_label = get_label_and_image_file(\"/mnt/data1/model_1122/image_classifier/test/no_target\", 2, files_and_label)\n",
    "random_files_and_label_elements = random.sample(files_and_label, 1000)\n",
    "print(f\"原始数据个数:{len(files_and_label)},随机选择的元素个数:{len(random_files_and_label_elements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "预测图片得到分类:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5761], device='cuda:0') tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_and_labels = []\n",
    "import torch.nn.functional as F\n",
    "for image_path, label in tqdm(random_files_and_label_elements, desc=\"预测图片得到分类\"):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        image_content = file.read()\n",
    "    image = process_image_classifier_image(image_content, torch_transforms, device)\n",
    "    if image is None:\n",
    "        continue\n",
    "    image = image.unsqueeze(0)\n",
    "    outputs = model(image)\n",
    "    max_prob, predicted_class = torch.max(\n",
    "        F.softmax(outputs, dim=1), dim=1)\n",
    "    print(max_prob, predicted_class)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 0), (2, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(predict_and_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "from typing import List, Union, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_metrics(predict_and_labels, \n",
    "                     metric_names: List[str] = [\"accuracy\", \"precision\", \"recall\", \"f1\"]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate multiple metrics between predictions and ground truth\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of predicted values\n",
    "        references: List of ground truth values\n",
    "        metric_names: List of metrics to calculate\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing calculated metrics\n",
    "    \"\"\"\n",
    "    predictions, references = zip(*predict_and_labels)\n",
    "    if len(predictions) != len(references):\n",
    "        raise ValueError(f\"Length mismatch: predictions ({len(predictions)}) != references ({len(references)})\")\n",
    "        \n",
    "    results = {}\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        metric = load(metric_name)\n",
    "        if metric_name == \"accuracy\":\n",
    "            result = metric.compute(predictions=predictions, references=references)\n",
    "        else:\n",
    "            result = metric.compute(predictions=predictions, references=references, average='macro')\n",
    "        results.update(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657d39d042f14559a91ba23ec3c77529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acb48c6b3814162a0cea09d19f0ec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.942242355605889, 'precision': 0.9408027593630216, 'recall': 0.9509068626620701, 'f1': 0.944641139188016}\n"
     ]
    }
   ],
   "source": [
    "print(calculate_metrics(predict_and_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, references = zip(*predict_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 2, 0, 0, 0, 0, 0, 1, 0) (0, 0, 2, 0, 0, 0, 0, 0, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:10], references[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
